{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW7XvzSv23q6FFXvqM6aJ6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFDicI3bXKFC"
      },
      "outputs": [],
      "source": [
        "# Idea evaluator based on Sakana's paper level evaluator\n",
        "# Simple prompt based evaluator with few-shot examples\n",
        "# Prompt and scoring guidelines taken from NeurIPS 2024 guidelines\n",
        "# No external tool provided\n",
        "# Assuming list of idea input\n",
        "# Prompts updated for idea review\n",
        "# Supports ensemble (multiple calls to the same model for review)\n",
        "# Supports statistical aggregation\n",
        "# TODO: Using LLM metareview to aggregate\n",
        "# Saves JSONL with reviews per idea"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLM Calling Functions"
      ],
      "metadata": {
        "id": "PXTzIi_AgTHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting OpenRouter API Key\n",
        "from google.colab import userdata\n",
        "openrouter_api_key = userdata.get('OpenRouter_Key')\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from typing import Optional\n",
        "import re"
      ],
      "metadata": {
        "id": "cWSruYawgSbk"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_ai_request(user_message, system_prompt=Optional, model=\"google/gemini-2.5-pro-preview-03-25\", file=Optional, file_data=Optional, file_name=Optional, temperature=0.7):\n",
        "    \"\"\"Send a request to the OpenRouter API and return the response\"\"\"\n",
        "    # Construction message\n",
        "    messages_array = []\n",
        "    if system_prompt:\n",
        "      system_prompt_message = {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": system_prompt\n",
        "      }\n",
        "      messages_array.append(system_prompt_message)\n",
        "\n",
        "    user_message_prompt_message = [{\n",
        "        \"type\": \"text\",\n",
        "        \"text\": user_message\n",
        "    }]\n",
        "    if file:\n",
        "        user_message_prompt_message.append({\n",
        "            \"type\": \"file\",\n",
        "            \"file\": {\n",
        "            \"filename\": file_name,\n",
        "            \"file_data\": file_data\n",
        "            }\n",
        "        }\n",
        "        )\n",
        "    user_message_prompt_message = str(user_message_prompt_message)\n",
        "\n",
        "    user_message = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_message_prompt_message\n",
        "    }\n",
        "\n",
        "    messages_array.append(user_message)\n",
        "\n",
        "    response = requests.post(\n",
        "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {openrouter_api_key}\"\n",
        "        },\n",
        "        data=json.dumps({\n",
        "            \"model\": model,\n",
        "            \"messages\": messages_array,\n",
        "            \"temperature\": temperature,\n",
        "            # \"max_tokens\": 5000,\n",
        "            \"transforms\" : [\"middle-out\"]\n",
        "        })\n",
        "    )\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "i7H_gEcAir8C"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_ai_response(response, reasoning=False):\n",
        "    \"\"\"Extract the content and usage metrics from API response\"\"\"\n",
        "    try:\n",
        "        content = response['choices'][0]['message']['content']\n",
        "        usage = response['usage']\n",
        "        if reasoning:\n",
        "            reasoning_text = response['choices'][0]['message']['reasoning']\n",
        "            return {\n",
        "              'content': content,\n",
        "              'usage': usage,\n",
        "              'reasoning': reasoning_text,\n",
        "              'success': True\n",
        "          }\n",
        "        elif reasoning is False:\n",
        "            return {\n",
        "              'content': content,\n",
        "              'usage': usage,\n",
        "              'success': True\n",
        "          }\n",
        "    except (KeyError, IndexError) as e:\n",
        "        return {\n",
        "            'content': None,\n",
        "            'usage': None,\n",
        "            'success': False,\n",
        "            'reasoning': None,\n",
        "            'error': str(e),\n",
        "            'response': response\n",
        "        }"
      ],
      "metadata": {
        "id": "bHxIFFu1iv-7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_json_between_markers(llm_output: str) -> dict | None:\n",
        "    # Regular expression pattern to find JSON content between ```json and ```\n",
        "    json_pattern = r\"```json(.*?)```\"\n",
        "    matches = re.findall(json_pattern, llm_output, re.DOTALL)\n",
        "\n",
        "    if not matches:\n",
        "        # Fallback: Try to find any JSON-like content in the output\n",
        "        json_pattern = r\"\\{.*?\\}\"\n",
        "        matches = re.findall(json_pattern, llm_output, re.DOTALL)\n",
        "\n",
        "    for json_string in matches:\n",
        "        json_string = json_string.strip()\n",
        "        try:\n",
        "            parsed_json = json.loads(json_string)\n",
        "            return parsed_json\n",
        "        except json.JSONDecodeError:\n",
        "            # Attempt to fix common JSON issues\n",
        "            try:\n",
        "                # Remove invalid control characters\n",
        "                json_string_clean = re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", json_string)\n",
        "                parsed_json = json.loads(json_string_clean)\n",
        "                return parsed_json\n",
        "            except json.JSONDecodeError:\n",
        "                continue  # Try next match\n",
        "\n",
        "    return None  # No valid JSON found"
      ],
      "metadata": {
        "id": "JcNEpmyNt2u6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reviewer Prompt Creation"
      ],
      "metadata": {
        "id": "K2HdbTz8gVvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviewer_system_prompt_base = \"You are an AI researcher who is reviewing a research idea submitted by a peer for evaluation. Be critical and cautious in your decision.\""
      ],
      "metadata": {
        "id": "_57bPuVvm_S7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing focus on Limitations and Ethical Concerns, Presentation and Soundness\n",
        "# Rewrote the Summary section to focus on idea\n",
        "# Reworded NeurIPS community to AI Research community\n",
        "# Removed Overall, Decision\n",
        "\n",
        "neurips_form_guidelines = \"\"\"\n",
        "## Idea Review Form\n",
        "Below is a description of the questions you will be asked on the idea review form for each idea and some guidelines on what to consider when answering these questions.\n",
        "When writing your review, please keep in mind that after decisions have been made, reviews and meta-reviews of accepted ideas and opted-in rejected ideas will be made public.\n",
        "\n",
        "1. Summary: Briefly summarize the idea and its contributions. This is not the place to critique the idea; the authors should generally agree with a well-written summary.\n",
        "2. Strengths and Weaknesses: Please provide a thorough assessment of the strengths and weaknesses of the idea.\n",
        "3. Originality: Are the tasks or methods new? Is the work a novel combination of well-known techniques? (This can be valuable!) Is it clear how this work differs from previous contributions? Is related work adequately cited\n",
        "4. Quality: Is the idea technically sound? Are the claims well supported (e.g., by potential theoretical frameworks or concrete experimental approaches)? Are the proposed methods appropriate and feasible given current technology? Does the idea clearly articulate how it would be validated or tested?\n",
        "5. Clarity: Is the idea clearly written? Is it well organized? (If not, please make constructive suggestions for improving its clarity.) Does it adequately inform the reader? (Note that a superbly written idea provides enough information for an expert reader to gauge its relevance.)\n",
        "6. Significance: Are the possible results from the idea important? Are others (researchers or practitioners) likely to use the ideas or build on them? Does the idea address a difficult task in a better way than previous work? Does it advance the state of the art in a demonstrable way? Does it suggest unique data, unique conclusions about existing data, or a unique theoretical or experimental approach?\n",
        "7. Questions: Please list up and carefully describe any questions and suggestions for the authors. Think of the things where a response from the author can change your opinion, clarify a confusion or address a limitation. This can be very important for a productive rebuttal and discussion phase with the authors.\n",
        "\n",
        "8. Contribution: Please assign the idea a numerical rating on the following scale to indicate the quality of the overall contribution this idea makes to the research area being studied. Are the questions being asked important? Does the idea bring a significant originality of ideas and/or execution? Are the results valuable to share with the broader AI research community.\n",
        "  4: excellent\n",
        "  3: good\n",
        "  2: fair\n",
        "  1: poor\n",
        "\n",
        "9. Confidence:  Please provide a \"confidence score\" for your assessment of this submission to indicate how confident you are in your evaluation. Choices:\n",
        "  5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\n",
        "  4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\n",
        "  3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\n",
        "  2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\n",
        "  1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9nhyn2cjnQM4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_instructions = \"\"\"\n",
        "Respond in the following format:\n",
        "\n",
        "THOUGHT:\n",
        "<THOUGHT>\n",
        "\n",
        "REVIEW JSON:\n",
        "```json\n",
        "<JSON>\n",
        "```\n",
        "\n",
        "In <THOUGHT>, first briefly discuss your intuitions and reasoning for the evaluation.\n",
        "Detail your high-level arguments, necessary choices and desired outcomes of the review.\n",
        "Do not make generic comments here, but be specific to your current idea.\n",
        "Treat this as the note-taking phase of your review.\n",
        "\n",
        "In <JSON>, provide the review in JSON format with the following fields in the order:\n",
        "- \"Summary\": A summary of the paper content and its contributions.\n",
        "- \"Strengths\": A list of strengths of the paper.\n",
        "- \"Weaknesses\": A list of weaknesses of the paper.\n",
        "- \"Originality\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Quality\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Clarity\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Significance\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Questions\": A set of clarifying questions to be answered by the paper authors.\n",
        "- \"Contribution\": A rating from 1 to 4 (poor, fair, good, excellent).\n",
        "- \"Confidence\": A rating from 1 to 5 (low, medium, high, very high, absolute).\n",
        "\n",
        "This JSON will be automatically parsed, so ensure the format is precise.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UaHLsbRKpQNl"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_review_prompt(prompt_base, guidelines, output_instructions, include_few_shot=False, few_shot_examples=None):\n",
        "    prompt = prompt_base + guidelines\n",
        "    prompt += output_instructions\n",
        "    if include_few_shot:\n",
        "        prompt += few_shot_examples\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "7pC1xcoYspPq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reviewing Single Idea Text"
      ],
      "metadata": {
        "id": "OqBMku4Dt4zP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JjQ80ObN4y4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def review_single_idea(idea_text, reviewer_prompt, ensemble: int = 1, model: str = \"google/gemini-2.5-pro-preview-03-25\"):\n",
        "  # creating user_message\n",
        "  print(\"Creating user message.\")\n",
        "  user_message = f\"\"\"\n",
        "    Here is the idea you are asked to review:\n",
        "    ```\n",
        "    {idea_text}\n",
        "    ```\n",
        "    \"\"\"\n",
        "  review_results = []\n",
        "  review_count = 1 # Minimum\n",
        "  if ensemble:\n",
        "    review_count = ensemble\n",
        "  print(f\"Starting review calls for ensemble length: {review_count}\")\n",
        "  for i in range(ensemble):\n",
        "    print(f\"Review # : {i} with {model}\")\n",
        "    review_raw_response = send_ai_request(user_message=user_message, system_prompt=reviewer_prompt, model=model, temperature=0.75)\n",
        "    print(f\"Review # : {i} with {model} - Raw response received.\")\n",
        "    review_response_parsed = parse_ai_response(review_raw_response)\n",
        "    print(f\"Review # : {i} with {model} - Raw response parsed.\")\n",
        "    review_response_json = extract_json_between_markers(review_response_parsed['content'])\n",
        "    print(f\"Review # : {i} with {model} - Score JSON from parsed response extracted.\")\n",
        "    review_object = {\n",
        "        \"review_count\" : i,\n",
        "        \"review_raw_response\" : review_raw_response,\n",
        "        \"review_response_parsed\" : review_response_parsed,\n",
        "        \"review_response_json\" : review_response_json,\n",
        "        \"model\" : model\n",
        "    }\n",
        "    review_results.append(review_object)\n",
        "    print(f\"Review # : {i} with {model} - Appended to review results array.\")\n",
        "    i += 1\n",
        "    print(f\"Moving on to review # : {i}\")\n",
        "  return review_results"
      ],
      "metadata": {
        "id": "m_lnIault7BB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Processing Module"
      ],
      "metadata": {
        "id": "5XG0_tjB0tE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv"
      ],
      "metadata": {
        "id": "rId7Bygs2jXl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ideas(file_path):\n",
        "    \"\"\"\n",
        "    Load idea records from a JSONL or CSV file.\n",
        "\n",
        "    Returns:\n",
        "      List[dict] each with keys:\n",
        "        - id: str (simple incremental, e.g. idea_001, idea_002, …)\n",
        "        - text: str (idea text)\n",
        "        - original_data: dict (all fields from the source)\n",
        "    \"\"\"\n",
        "    ideas = []\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    counter = 1\n",
        "\n",
        "    if ext == '.jsonl':\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            for lineno, line in enumerate(f, start=1):\n",
        "                try:\n",
        "                    item = json.loads(line)\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"Skipping malformed JSONL line {lineno}\")\n",
        "                    continue\n",
        "\n",
        "                text = item.get('text', '').strip()\n",
        "                if not text:\n",
        "                    print(f\"Skipping empty text at JSONL line {lineno}\")\n",
        "                    continue\n",
        "\n",
        "                idea_id = f\"idea_{counter:03d}\"\n",
        "                counter += 1\n",
        "                ideas.append({\n",
        "                    'id': idea_id,\n",
        "                    'text': text,\n",
        "                    'original_data': item\n",
        "                })\n",
        "\n",
        "    elif ext == '.csv':\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for rowno, row in enumerate(reader, start=2):  # header is row 1\n",
        "                # prefer an 'idea_text' column if present\n",
        "                text = row.get('idea_text') or row.get('text') or row.get('description') or ''\n",
        "                text = text.strip()\n",
        "                if not text:\n",
        "                    print(f\"Skipping empty text at CSV row {rowno}\")\n",
        "                    continue\n",
        "\n",
        "                idea_id = f\"idea_{counter:03d}\"\n",
        "                counter += 1\n",
        "                ideas.append({\n",
        "                    'id': idea_id,\n",
        "                    'text': text,\n",
        "                    'original_data': row\n",
        "                })\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {ext}\")\n",
        "\n",
        "    return ideas\n"
      ],
      "metadata": {
        "id": "Vm7N9U-uuxiM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregating Reviews Across Ensemble"
      ],
      "metadata": {
        "id": "5OftIXbKDl83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import statistics\n",
        "\n",
        "def aggregate_reviews(raw_jsons):\n",
        "    # raw_jsons: list of dicts from review_response_json\n",
        "    agg = {}\n",
        "    # 1) Numeric fields\n",
        "    for field in (\"Originality\",\"Quality\",\"Clarity\",\"Significance\",\"Contribution\",\"Confidence\"):\n",
        "        vals = [r[field] for r in raw_jsons if field in r]\n",
        "        agg[field] = int(round(statistics.mean(vals)))\n",
        "\n",
        "    # 2) Text summary – pick the 1st (or concatenate if you like)\n",
        "    agg[\"Summary\"] = raw_jsons[0][\"Summary\"]\n",
        "\n",
        "    # 3) Strengths & Weaknesses – majority vote\n",
        "    for list_field in (\"Strengths\",\"Weaknesses\"):\n",
        "      agg[list_field] = set(q for r in raw_jsons for q in r[list_field])\n",
        "\n",
        "    # 4) Questions – union\n",
        "    questions = set(q for r in raw_jsons for q in r[\"Questions\"])\n",
        "    agg[\"Questions\"] = list(questions)\n",
        "\n",
        "    return agg"
      ],
      "metadata": {
        "id": "wn5juv3zDpsc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Generation"
      ],
      "metadata": {
        "id": "x3nk5Nk0Hjgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def save_raw_reviews_to_jsonl(ideas, output_path):\n",
        "    \"\"\"\n",
        "    Persist the batch review output to a JSONL file.\n",
        "\n",
        "    Args:\n",
        "      ideas (List[dict]):\n",
        "        Each dict should have keys 'id', 'text', 'original_data', and 'review_results'\n",
        "        where 'review_results' is the list returned by review_single_idea.\n",
        "      output_path (str): path to write the .jsonl file.\n",
        "    \"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as fout:\n",
        "        for idea in ideas:\n",
        "            # Build a clean record for this idea\n",
        "            record = {\n",
        "                \"id\": idea[\"id\"],\n",
        "                \"text\": idea[\"text\"],\n",
        "                # \"original_data\": idea.get(\"original_data\", {}),\n",
        "                \"reviews\": []\n",
        "            }\n",
        "\n",
        "            for r in idea.get(\"review_results\", []):\n",
        "                # Pull out the fields you want\n",
        "                review_entry = {\n",
        "                    \"model\": r.get(\"model\"),\n",
        "                    \"parsed_json\": r.get(\"review_response_json\"),\n",
        "                    # \"raw_content\": r.get(\"review_response_parsed\", {}).get(\"content\"),\n",
        "                    \"prompt_tokens\": r.get(\"review_response_parsed\", {}).get(\"usage\").get(\"prompt_tokens\"),\n",
        "                    \"completion_tokens\": r.get(\"review_response_parsed\", {}).get(\"usage\").get(\"completion_tokens\")\n",
        "                }\n",
        "                record[\"reviews\"].append(review_entry)\n",
        "\n",
        "            fout.write(json.dumps(record) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "M35rQTWdHk_o"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Run"
      ],
      "metadata": {
        "id": "q9pEUYST2xYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Setting system prompt.\")\n",
        "system_prompt = build_review_prompt(prompt_base=reviewer_system_prompt_base, guidelines=neurips_form_guidelines, output_instructions=template_instructions, include_few_shot=False, few_shot_examples=None)\n",
        "\n",
        "print(\"Fetching list of ideas.\")\n",
        "list_of_ideas_file_path = input(\"Enter file path.\")\n",
        "ideas = load_ideas(list_of_ideas_file_path)\n",
        "print(f\"Type of ideas: {type(ideas)}\")\n",
        "print(f\"Number of ideas loaded: {len(ideas)}\")\n",
        "\n",
        "print(\"Starting ensemble review process.\")\n",
        "for idea in ideas:\n",
        "    print(f\"Reviewing idea: {idea['id']}\")\n",
        "    review_results = review_single_idea(idea_text=idea['text'], reviewer_prompt=system_prompt, ensemble=2, model=\"openai/gpt-4o\")\n",
        "    idea[\"review_results\"] = review_results\n",
        "    print(f\"Review complete for idea: {idea['id']}\")\n",
        "\n",
        "print(\"Reviewing output per idea:\")\n",
        "for idea in ideas:\n",
        "  print(f\"Idea ID: {idea['id']}\")\n",
        "  print(f\"Review Extracted JSON from Content: {idea['review_results'][0]['review_response_json']}\")\n",
        "  print(f\"Review Content Extracted from Raw: {idea['review_results'][0]['review_response_parsed']}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BCemJxtpAv5I",
        "outputId": "24e65570-b4ee-4f5d-f4ea-67aee0a9bf5e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting system prompt.\n",
            "Fetching list of ideas.\n",
            "Enter file path./content/test_ideas.jsonl\n",
            "Type of ideas: <class 'list'>\n",
            "Number of ideas loaded: 3\n",
            "Starting ensemble review process.\n",
            "Reviewing idea: idea_001\n",
            "Creating user message.\n",
            "Starting review calls for ensemble length: 2\n",
            "Review # : 0 with openai/gpt-4o\n",
            "Review # : 0 with openai/gpt-4o - Raw response received.\n",
            "Review # : 0 with openai/gpt-4o - Raw response parsed.\n",
            "Review # : 0 with openai/gpt-4o - Score JSON from parsed response extracted.\n",
            "Review # : 0 with openai/gpt-4o - Appended to review results array.\n",
            "Moving on to review # : 1\n",
            "Review # : 1 with openai/gpt-4o\n",
            "Review # : 1 with openai/gpt-4o - Raw response received.\n",
            "Review # : 1 with openai/gpt-4o - Raw response parsed.\n",
            "Review # : 1 with openai/gpt-4o - Score JSON from parsed response extracted.\n",
            "Review # : 1 with openai/gpt-4o - Appended to review results array.\n",
            "Moving on to review # : 2\n",
            "Review complete for idea: idea_001\n",
            "Reviewing idea: idea_002\n",
            "Creating user message.\n",
            "Starting review calls for ensemble length: 2\n",
            "Review # : 0 with openai/gpt-4o\n",
            "Review # : 0 with openai/gpt-4o - Raw response received.\n",
            "Review # : 0 with openai/gpt-4o - Raw response parsed.\n",
            "Review # : 0 with openai/gpt-4o - Score JSON from parsed response extracted.\n",
            "Review # : 0 with openai/gpt-4o - Appended to review results array.\n",
            "Moving on to review # : 1\n",
            "Review # : 1 with openai/gpt-4o\n",
            "Review # : 1 with openai/gpt-4o - Raw response received.\n",
            "Review # : 1 with openai/gpt-4o - Raw response parsed.\n",
            "Review # : 1 with openai/gpt-4o - Score JSON from parsed response extracted.\n",
            "Review # : 1 with openai/gpt-4o - Appended to review results array.\n",
            "Moving on to review # : 2\n",
            "Review complete for idea: idea_002\n",
            "Reviewing idea: idea_003\n",
            "Creating user message.\n",
            "Starting review calls for ensemble length: 2\n",
            "Review # : 0 with openai/gpt-4o\n",
            "Review # : 0 with openai/gpt-4o - Raw response received.\n",
            "Review # : 0 with openai/gpt-4o - Raw response parsed.\n",
            "Review # : 0 with openai/gpt-4o - Score JSON from parsed response extracted.\n",
            "Review # : 0 with openai/gpt-4o - Appended to review results array.\n",
            "Moving on to review # : 1\n",
            "Review # : 1 with openai/gpt-4o\n",
            "Review # : 1 with openai/gpt-4o - Raw response received.\n",
            "Review # : 1 with openai/gpt-4o - Raw response parsed.\n",
            "Review # : 1 with openai/gpt-4o - Score JSON from parsed response extracted.\n",
            "Review # : 1 with openai/gpt-4o - Appended to review results array.\n",
            "Moving on to review # : 2\n",
            "Review complete for idea: idea_003\n",
            "Reviewing output per idea:\n",
            "Idea ID: idea_001\n",
            "Review Extracted JSON from Content: {'Summary': 'The proposal suggests using Generative Adversarial Networks (GANs) to simulate missing seismic waveforms. This approach aims to fill gaps in seismic data, which could improve the analysis and interpretation of seismic events.', 'Strengths': ['Addresses a practical problem in the field of seismology.', 'Utilizes GANs, which are known for their ability to generate realistic data.', 'Could potentially improve the quality of seismic data analysis.'], 'Weaknesses': ['The originality of applying GANs to this problem is not clear without further context.', 'The proposal lacks details on how the GANs will be trained and validated.', 'It is not clear how the proposed method compares to existing methods for simulating missing seismic data.'], 'Originality': 2, 'Quality': 2, 'Clarity': 2, 'Significance': 3, 'Questions': ['How does this approach differ from previous applications of GANs to seismic data?', 'What specific metrics will be used to validate the effectiveness of the simulated waveforms?', 'Are there any existing methods for simulating missing seismic waveforms and how does this method compare?', 'What datasets will be used for training and testing the GANs?'], 'Contribution': 2, 'Confidence': 3}\n",
            "Review Content Extracted from Raw: {'content': 'THOUGHT:\\nThe submission proposes using Generative Adversarial Networks (GANs) to simulate missing seismic waveforms. This is an interesting application of GANs, a type of deep learning model known for generating realistic data. The idea seems potentially valuable because seismic data can be incomplete due to various factors, and accurately simulating missing data can enhance seismic analysis and interpretation. However, I must consider the novelty of applying GANs to this problem, the technical soundness of the approach, and the clarity and significance of the contribution. I will also evaluate whether related works have been adequately cited and if the proposal outlines a clear validation strategy.\\n\\nREVIEW JSON:\\n```json\\n{\\n  \"Summary\": \"The proposal suggests using Generative Adversarial Networks (GANs) to simulate missing seismic waveforms. This approach aims to fill gaps in seismic data, which could improve the analysis and interpretation of seismic events.\",\\n  \"Strengths\": [\\n    \"Addresses a practical problem in the field of seismology.\",\\n    \"Utilizes GANs, which are known for their ability to generate realistic data.\",\\n    \"Could potentially improve the quality of seismic data analysis.\"\\n  ],\\n  \"Weaknesses\": [\\n    \"The originality of applying GANs to this problem is not clear without further context.\",\\n    \"The proposal lacks details on how the GANs will be trained and validated.\",\\n    \"It is not clear how the proposed method compares to existing methods for simulating missing seismic data.\"\\n  ],\\n  \"Originality\": 2,\\n  \"Quality\": 2,\\n  \"Clarity\": 2,\\n  \"Significance\": 3,\\n  \"Questions\": [\\n    \"How does this approach differ from previous applications of GANs to seismic data?\",\\n    \"What specific metrics will be used to validate the effectiveness of the simulated waveforms?\",\\n    \"Are there any existing methods for simulating missing seismic waveforms and how does this method compare?\",\\n    \"What datasets will be used for training and testing the GANs?\"\\n  ],\\n  \"Contribution\": 2,\\n  \"Confidence\": 3\\n}\\n```', 'usage': {'prompt_tokens': 1165, 'completion_tokens': 425, 'total_tokens': 1590, 'prompt_tokens_details': {'cached_tokens': 1152}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'success': True}\n",
            "Idea ID: idea_002\n",
            "Review Extracted JSON from Content: {'Summary': 'The proposal suggests developing an AI agent that automates the hyperparameter tuning process in machine learning models using reinforcement learning techniques. The aim is to streamline the tuning process, making it more efficient and less reliant on manual expert intervention.', 'Strengths': ['Addresses a significant challenge in machine learning by automating hyperparameter tuning.', 'Potential to save time and resources in model development.', 'Could make hyperparameter tuning more accessible to non-experts.'], 'Weaknesses': ['Reinforcement learning can be computationally expensive, which might offset some of the efficiency gains.', 'The novelty of the approach is questionable, as similar methods have been explored in previous research.', 'The proposal lacks detail on how the method would be validated or tested.'], 'Originality': 2, 'Quality': 2, 'Clarity': 3, 'Significance': 3, 'Questions': ['How does this approach differ from existing methods that use RL for hyperparameter tuning?', 'What specific reinforcement learning algorithms will be used, and why?', 'How will the success of the hyperparameter tuning agent be measured?', 'What computational resources are required to implement this method effectively?'], 'Contribution': 2, 'Confidence': 4}\n",
            "Review Content Extracted from Raw: {'content': 'THOUGHT:\\nThe idea of automating hyperparameter tuning through reinforcement learning (RL) is an intriguing one. Hyperparameter tuning is a critical task in machine learning that can greatly affect model performance, but it is often labor-intensive and requires expert knowledge. By leveraging RL, the process could potentially become more efficient and accessible, reducing the need for manual intervention and potentially improving performance. However, it\\'s essential to assess how novel this approach is, as there have been several existing works exploring similar ideas. The quality of the proposal will depend on the technical soundness, feasibility, and how it plans to measure success. Clarity will be essential to understand the methodology proposed, and the significance will be judged by its potential impact on the field. Finally, I will consider any potential pitfalls or limitations that may arise.\\n\\nREVIEW JSON:\\n```json\\n{\\n  \"Summary\": \"The proposal suggests developing an AI agent that automates the hyperparameter tuning process in machine learning models using reinforcement learning techniques. The aim is to streamline the tuning process, making it more efficient and less reliant on manual expert intervention.\",\\n  \"Strengths\": [\\n    \"Addresses a significant challenge in machine learning by automating hyperparameter tuning.\",\\n    \"Potential to save time and resources in model development.\",\\n    \"Could make hyperparameter tuning more accessible to non-experts.\"\\n  ],\\n  \"Weaknesses\": [\\n    \"Reinforcement learning can be computationally expensive, which might offset some of the efficiency gains.\",\\n    \"The novelty of the approach is questionable, as similar methods have been explored in previous research.\",\\n    \"The proposal lacks detail on how the method would be validated or tested.\"\\n  ],\\n  \"Originality\": 2,\\n  \"Quality\": 2,\\n  \"Clarity\": 3,\\n  \"Significance\": 3,\\n  \"Questions\": [\\n    \"How does this approach differ from existing methods that use RL for hyperparameter tuning?\",\\n    \"What specific reinforcement learning algorithms will be used, and why?\",\\n    \"How will the success of the hyperparameter tuning agent be measured?\",\\n    \"What computational resources are required to implement this method effectively?\"\\n  ],\\n  \"Contribution\": 2,\\n  \"Confidence\": 4\\n}\\n```', 'usage': {'prompt_tokens': 1169, 'completion_tokens': 449, 'total_tokens': 1618, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'success': True}\n",
            "Idea ID: idea_003\n",
            "Review Extracted JSON from Content: {'Summary': 'The proposal suggests creating a knowledge graph of AI Scientist papers to facilitate meta-analysis. This would involve structuring and interlinking research papers in AI, potentially aiding in the discovery of related work and insights.', 'Strengths': ['Addresses a significant challenge in AI research: organizing and accessing a large body of literature.', 'Potentially enhances the discovery of related research and insights.', 'Could provide a valuable tool for researchers to perform meta-analysis.'], 'Weaknesses': ['Lacks details on the methodology for constructing the knowledge graph.', 'Unclear how the meta-analysis will be conducted and what specific insights it aims to provide.', 'Potentially high complexity and resource intensity given the volume of AI research literature.'], 'Originality': 3, 'Quality': 2, 'Clarity': 2, 'Significance': 3, 'Questions': ['What specific methodologies will be used to construct the knowledge graph?', 'How will the completeness and accuracy of the knowledge graph be ensured?', 'What are the specific goals of the meta-analysis and how will success be measured?', 'How does this approach differ from existing databases or citation networks in AI research?'], 'Contribution': 2, 'Confidence': 3}\n",
            "Review Content Extracted from Raw: {'content': 'THOUGHT:\\nThe proposed idea is to create a knowledge graph of AI Scientist papers for meta-analysis. This concept inherently aims to structure and interlink research papers in AI, potentially improving the accessibility and discovery of related work and insights. While the idea is intriguing and could significantly facilitate research in the AI domain, it hinges on several critical aspects such as the quality and comprehensiveness of the data, the methodology for constructing the knowledge graph, and how the meta-analysis would be conducted and utilized. \\n\\nKey points for evaluation will include the novelty of applying knowledge graphs to this domain (since knowledge graphs are a well-known technology), the technical feasibility of the approach given the complexity and volume of AI research, and the clarity of the proposal in terms of execution and expected outcomes. The significance of the idea could be substantial if it effectively improves the way researchers interact with AI literature, but this depends heavily on implementation details and user engagement.\\n\\nREVIEW JSON:\\n```json\\n{\\n    \"Summary\": \"The proposal suggests creating a knowledge graph of AI Scientist papers to facilitate meta-analysis. This would involve structuring and interlinking research papers in AI, potentially aiding in the discovery of related work and insights.\",\\n    \"Strengths\": [\\n        \"Addresses a significant challenge in AI research: organizing and accessing a large body of literature.\",\\n        \"Potentially enhances the discovery of related research and insights.\",\\n        \"Could provide a valuable tool for researchers to perform meta-analysis.\"\\n    ],\\n    \"Weaknesses\": [\\n        \"Lacks details on the methodology for constructing the knowledge graph.\",\\n        \"Unclear how the meta-analysis will be conducted and what specific insights it aims to provide.\",\\n        \"Potentially high complexity and resource intensity given the volume of AI research literature.\"\\n    ],\\n    \"Originality\": 3,\\n    \"Quality\": 2,\\n    \"Clarity\": 2,\\n    \"Significance\": 3,\\n    \"Questions\": [\\n        \"What specific methodologies will be used to construct the knowledge graph?\",\\n        \"How will the completeness and accuracy of the knowledge graph be ensured?\",\\n        \"What are the specific goals of the meta-analysis and how will success be measured?\",\\n        \"How does this approach differ from existing databases or citation networks in AI research?\"\\n    ],\\n    \"Contribution\": 2,\\n    \"Confidence\": 3\\n}\\n```', 'usage': {'prompt_tokens': 1167, 'completion_tokens': 471, 'total_tokens': 1638, 'prompt_tokens_details': {'cached_tokens': 1024}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'success': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idea in ideas:\n",
        "  print(f\"Idea ID: {idea['id']}\")\n",
        "  print(f\"Number of Reviews for Idea: {len(idea['review_results'])}\")\n",
        "  raw_review_json_list = []\n",
        "  for i in range(len(idea['review_results'])):\n",
        "    print(f\"Review {i}\")\n",
        "    print(f\"Model: {idea['review_results'][i]['model']}\")\n",
        "    raw_review_json_list.append(idea['review_results'][i]['review_response_json'])\n",
        "\n",
        "  print(\"Getting simple aggregate\")\n",
        "  agg = aggregate_reviews(raw_review_json_list)\n",
        "  for key in agg:\n",
        "    print(f\"{key}: {agg[key]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2ZzmWK4fNpss",
        "outputId": "b55a9d07-2e84-4b7b-b75c-302a7d99dae3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Idea ID: idea_001\n",
            "Number of Reviews for Idea: 2\n",
            "Review 0\n",
            "Model: openai/gpt-4o\n",
            "Review 1\n",
            "Model: openai/gpt-4o\n",
            "Getting simple aggregate\n",
            "Originality: 2\n",
            "Quality: 2\n",
            "Clarity: 2\n",
            "Significance: 3\n",
            "Contribution: 2\n",
            "Confidence: 4\n",
            "Summary: The proposal suggests using Generative Adversarial Networks (GANs) to simulate missing seismic waveforms. This approach aims to fill gaps in seismic data, which could improve the analysis and interpretation of seismic events.\n",
            "Strengths: {'Could potentially improve the quality of seismic data analysis.', 'Potential to improve the accuracy of earthquake data analysis.', 'Innovative application of GANs to a significant problem in seismology.', 'Addresses a practical problem in the field of seismology.', 'Utilizes GANs, which are known for their ability to generate realistic data.'}\n",
            "Weaknesses: {'It is not clear how the proposed method compares to existing methods for simulating missing seismic data.', 'Lack of detail on how the GANs will be specifically applied to seismic data.', \"Unclear validation strategy for the simulated data's accuracy and reliability.\", 'Potential challenges in training GANs with possibly limited seismic data.', 'The originality of applying GANs to this problem is not clear without further context.', 'The proposal lacks details on how the GANs will be trained and validated.'}\n",
            "Questions: ['What datasets will be used for training and testing the GANs?', 'How will the GAN model be trained given the potentially limited amount of seismic data?', 'Are there any existing methods for simulating missing seismic waveforms and how does this method compare?', 'How does this approach differ from previous applications of GANs to seismic data?', 'What specific metrics will be used to validate the effectiveness of the simulated waveforms?', 'What measures will be put in place to validate the accuracy and reliability of the simulated waveforms?', 'Are there any existing works that have applied GANs to similar problems in geophysics or seismology?']\n",
            "Idea ID: idea_002\n",
            "Number of Reviews for Idea: 2\n",
            "Review 0\n",
            "Model: openai/gpt-4o\n",
            "Review 1\n",
            "Model: openai/gpt-4o\n",
            "Getting simple aggregate\n",
            "Originality: 2\n",
            "Quality: 2\n",
            "Clarity: 3\n",
            "Significance: 3\n",
            "Contribution: 2\n",
            "Confidence: 4\n",
            "Summary: The proposal suggests developing an AI agent that automates the hyperparameter tuning process in machine learning models using reinforcement learning techniques. The aim is to streamline the tuning process, making it more efficient and less reliant on manual expert intervention.\n",
            "Strengths: {'Potential to save time and resources in model development.', 'Could lead to more effective and efficient machine learning models.', 'Addresses a significant challenge in machine learning by automating hyperparameter tuning.', 'Could make hyperparameter tuning more accessible to non-experts.', 'Potential to significantly reduce the time and effort required for model optimization.', 'Addresses an important and challenging aspect of machine learning - hyperparameter tuning.'}\n",
            "Weaknesses: {'Reinforcement learning can be computationally expensive, which might offset some of the efficiency gains.', \"Lacks clear differentiation from existing solutions like Google's AutoML and Vizier.\", 'The idea is not novel; similar approaches have been explored in existing literature.', 'The novelty of the approach is questionable, as similar methods have been explored in previous research.', 'Risk of high computational costs associated with reinforcement learning methods.', 'The proposal lacks detail on how the method would be validated or tested.'}\n",
            "Questions: ['What are the criteria for validating the effectiveness of the proposed method?', 'How does this approach differ from existing methods that use RL for hyperparameter tuning?', \"How does this RL-based approach differ from existing methods like Google's AutoML?\", 'How will the success of the hyperparameter tuning agent be measured?', 'What specific RL algorithms or techniques will be employed in this approach?', 'How do you plan to address the computational cost associated with RL?', 'What computational resources are required to implement this method effectively?', 'What specific reinforcement learning algorithms will be used, and why?']\n",
            "Idea ID: idea_003\n",
            "Number of Reviews for Idea: 2\n",
            "Review 0\n",
            "Model: openai/gpt-4o\n",
            "Review 1\n",
            "Model: openai/gpt-4o\n",
            "Getting simple aggregate\n",
            "Originality: 3\n",
            "Quality: 2\n",
            "Clarity: 2\n",
            "Significance: 3\n",
            "Contribution: 2\n",
            "Confidence: 4\n",
            "Summary: The proposal suggests creating a knowledge graph of AI Scientist papers to facilitate meta-analysis. This would involve structuring and interlinking research papers in AI, potentially aiding in the discovery of related work and insights.\n",
            "Strengths: {'Addresses a significant challenge in AI research: organizing and accessing a large body of literature.', 'Offers a structured approach for meta-analysis, which can be valuable for researchers and practitioners.', 'Addresses the challenge of managing and analyzing a large volume of AI research literature.', 'Could provide a valuable tool for researchers to perform meta-analysis.', 'Potentially enhances the discovery of related research and insights.', 'Could potentially highlight relationships and trends that are not immediately evident from individual papers.'}\n",
            "Weaknesses: {'Lacks details on the methodology for constructing the knowledge graph.', \"Potential challenges in ensuring the knowledge graph's accuracy and comprehensiveness are not addressed.\", 'Potentially high complexity and resource intensity given the volume of AI research literature.', 'The feasibility of implementing this idea is unclear, particularly concerning data sourcing and integration.', 'Unclear how the meta-analysis will be conducted and what specific insights it aims to provide.', 'Lacks specificity on how the knowledge graph will be constructed and maintained.'}\n",
            "Questions: ['What specific methodologies will be used to construct the knowledge graph?', 'How will the completeness and accuracy of the knowledge graph be ensured?', 'How does this approach differ from existing databases or citation networks in AI research?', 'What are the specific methods and technologies proposed for constructing the knowledge graph?', 'How will the system ensure the accuracy and currency of the data in the knowledge graph?', 'What is the intended use of the meta-analysis results, and who are the primary beneficiaries?', 'What data sources will be used, and how will the knowledge graph integrate with existing databases or systems?', 'What are the specific goals of the meta-analysis and how will success be measured?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: LLM Meta-Reviewer"
      ],
      "metadata": {
        "id": "EY3T0GXHNqQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TODO: Meta Reviewer\n",
        "# meta_reviewer_system_prompt = \"\"\"You are an Area Chair at a machine learning conference.\n",
        "# # You are in charge of meta-reviewing a paper that was reviewed by {reviewer_count} reviewers.\n",
        "# # Your job is to aggregate the reviews into a single meta-review in the same format.\n",
        "# # Be critical and cautious in your decision, find consensus, and respect the opinion of all the reviewers.\"\"\"\n",
        "\n",
        "# def get_meta_review(model, client, temperature, reviews):\n",
        "#     review_text = \"\"\n",
        "#     for i, r in enumerate(reviews):\n",
        "#         review_text += f\"\"\"\n",
        "# Review {i + 1}/{len(reviews)}:\n",
        "# ```\n",
        "# {json.dumps(r)}\n",
        "# ```\n",
        "# \"\"\"\n",
        "#     base_prompt = neurips_form + review_text\n",
        "#     llm_review, _ = get_response_from_llm(\n",
        "#         base_prompt,\n",
        "#         model=model,\n",
        "#         client=client,\n",
        "#         system_message=meta_reviewer_system_prompt.format(reviewer_count=len(reviews)),\n",
        "#         print_debug=False,\n",
        "#         msg_history=None,\n",
        "#         temperature=temperature,\n",
        "#     )\n",
        "#     meta_review = extract_json_between_markers(llm_review)\n",
        "#     return meta_review"
      ],
      "metadata": {
        "id": "iqO2EuVsMknA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}